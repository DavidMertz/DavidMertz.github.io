#!/usr/bin/env -S uvx --with click python@3.13
"""
Before running util-linux `hardlink`:

    % hardlink-dups ~/tmp/home.dups
    Number of duplicates: 602,264
       Total bytes saved: 16,326,564,927
     Existing hard links: 7,772

After running util-linux `hardlink`:

    % hardlink-dups --dry-run ~/tmp/home.dups
    Dry run completed.
    Number of duplicates: 351,652
       Total bytes saved: 12,092,711,235
     Existing hard links: 10,989
"""

from pathlib import Path

import click


def deduplicate(dedup_list, verbose):
    target = Path(dedup_list[0])
    if verbose:
        numdups = len(dedup_list) - 1
        count_mess = f"{len(dedup_list) - 1} duplicate{'s' if numdups-1 else ''} found"
        click.echo(f"Processing {target} with {count_mess}")
    for fname in dedup_list[1:]:
        _dup = Path(fname)


@click.command()
@click.argument(
    "filename",
    type=click.Path(exists=True),
)
@click.option(
    "-s",
    "--allow-symlinks",
    is_flag=True,
    help="Create symlinks across filesystems (otherwise ignore)",
)
@click.option(
    "--dry-run",
    is_flag=True,
    help="Perform a dry run without actually deleting duplicates",
)
@click.option(
    "-v",
    "--verbose",
    is_flag=True,
    help="Print verbose output",
)
def dedup(filename, dry_run, verbose, allow_symlinks):
    """
    The utility `find-dups` produces a report on duplicate files similar to
    the below (the extra blank lines are a quirk of this help doc):

      Size 117383456 | SHA1: 9646e8a7682588d6b2f2add1bb3045e11955e8a2

        /share/containers/storage/overlay/26f18d7413/diff/usr/local/bin/node
        /git/Vid/.venv/lib/python3.13/site-packages/playwright/driver/node
        /.cache/uv/archive-v0/9zomOyiUD4jDzkWfJG8G-/playwright/driver/node

      Size 110439272 | SHA1: <INODE 95965882>

        /git/Vid/.venv/lib/python3.13/site-packages/polars/polars.abi3.so
        /.cache/uv/archive-v0/9_JeSBUsO1T1AXGAoTI-P/polars/polars.abi3.so

    This utility will expect this format.  SHA sums indicate duplications;
    INODE items indicate existing hard links that will not be modified.
    """
    n_dups = 0
    n_bytes = 0
    n_hardlinks = 0
    size = 0
    dedup_list = []
    is_hardlink = False
    first_in_set = True
    with open(filename, "r") as file:
        for line in file:
            if line.startswith("Size "):
                if dedup_list and not dry_run:
                    # Perform the actual conversion of files to hard links
                    deduplicate(dedup_list, verbose)

                _size, identifier = line.strip().split("|")
                size = int(_size.split()[1])
                is_hardlink = identifier.lstrip().startswith("SHA1: <INODE")
                first_in_set = True
                dedup_list = []

            else:
                if is_hardlink:
                    n_hardlinks += 1
                else:
                    dedup_list.append(line.strip())
                    n_dups += 1
                    if first_in_set:
                        first_in_set = False
                    else:
                        n_bytes += size

    if not dry_run:
        # Perform the actual conversion of files to hard links
        pass  # TODO

    if dry_run:
        click.echo("Dry run completed.")
    click.echo(f"Number of duplicates: {n_dups:,}")
    click.echo(f"   Total bytes saved: {n_bytes:,}")
    click.echo(f" Existing hard links: {n_hardlinks:,}")


if __name__ == "__main__":
    dedup()
